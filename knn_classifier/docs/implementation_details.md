# ğŸ“„ implementation_details.md

# K-è¿‘é‚»ç®—æ³•å®ç°ç»†èŠ‚

## ğŸ§® æ•°å­¦åŸç†è¯¦è§£

### è·ç¦»åº¦é‡

#### æ¬§æ°è·ç¦» (Euclidean Distance)
```math
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
```
**å®ç°ä¼˜åŒ–**ï¼š
```python
# ä½¿ç”¨scipyçš„cdistè¿›è¡Œå‘é‡åŒ–è®¡ç®—ï¼Œé¿å…æ‰‹åŠ¨å¾ªç¯
distances = cdist(X, self.X_train, metric='euclidean')
```

#### æ›¼å“ˆé¡¿è·ç¦» (Manhattan Distance)
```math
d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
```
**å®ç°ç‰¹ç‚¹**ï¼š
```python
# å¯¹é«˜ç»´ç¨€ç–æ•°æ®æ›´æœ‰æ•ˆ
distances = cdist(X, self.X_train, metric='cityblock')
```

### æŠ•ç¥¨æœºåˆ¶

#### å‡åŒ€æŠ•ç¥¨ (Uniform Voting)
```math
\hat{y} = \arg\max_{c} \sum_{i=1}^{k} \mathbb{I}(y_i = c)
```

#### è·ç¦»åŠ æƒæŠ•ç¥¨ (Distance-Weighted Voting)
```math
\hat{y} = \arg\max_{c} \sum_{i=1}^{k} \frac{1}{d(x, x_i) + \epsilon} \cdot \mathbb{I}(y_i = c)
```
å…¶ä¸­ $\epsilon = 10^{-8}$ ç”¨äºé¿å…é™¤é›¶é”™è¯¯ã€‚

## ğŸ”§ æ ¸å¿ƒä»£ç è§£æ

### KNeighborsClassifier ç±»è®¾è®¡

```python
class KNeighborsClassifier:
    def __init__(self, n_neighbors=5, metric='euclidean', weights='uniform'):
        # å‚æ•°éªŒè¯å’Œåˆå§‹åŒ–
        self._validate_parameters(n_neighbors, metric, weights)
        
    def fit(self, X, y):
        """å­˜å‚¨è®­ç»ƒæ•°æ®ï¼ŒK-NNæ˜¯æƒ°æ€§å­¦ä¹ ç®—æ³•"""
        self.X_train = np.array(X)
        self.y_train = np.array(y)
        return self
        
    def predict(self, X):
        # 1. è®¡ç®—è·ç¦»çŸ©é˜µ
        distances = self._compute_distances(X)
        # 2. è·å–æœ€è¿‘é‚»å±…ç´¢å¼•
        indices = self._get_neighbor_indices(distances)
        # 3. åŸºäºé‚»å±…è¿›è¡Œé¢„æµ‹
        predictions = self._predict_from_neighbors(indices, distances)
        return predictions
```

### å…³é”®ç®—æ³•å®ç°

#### è·ç¦»è®¡ç®—ä¼˜åŒ–
```python
def _compute_distances(self, X):
    """ä½¿ç”¨scipyçš„cdistè¿›è¡Œé«˜æ•ˆçš„è·ç¦»è®¡ç®—"""
    if self.metric == 'euclidean':
        # æ¬§æ°è·ç¦»çš„å‘é‡åŒ–å®ç°ï¼Œæ¯”æ‰‹åŠ¨å¾ªç¯å¿«100å€ä»¥ä¸Š
        return cdist(X, self.X_train, metric='euclidean')
    elif self.metric == 'manhattan':
        return cdist(X, self.X_train, metric='cityblock')
```

#### é‚»å±…é€‰æ‹©ç­–ç•¥
```python
def _get_neighbor_indices(self, distances):
    """ä½¿ç”¨argpartitionè¿›è¡Œéƒ¨åˆ†æ’åºï¼Œæ—¶é—´å¤æ‚åº¦O(n)"""
    # åªå¯¹å‰kä¸ªæœ€å°è·ç¦»è¿›è¡Œæ’åºï¼Œè€Œä¸æ˜¯å…¨éƒ¨æ’åº
    indices = np.argpartition(distances, self.n_neighbors, axis=1)
    return indices[:, :self.n_neighbors]
```

#### åŠ æƒæŠ•ç¥¨å®ç°
```python
def _weighted_vote(self, labels, distances):
    """è·ç¦»åŠ æƒæŠ•ç¥¨ï¼Œå¤„ç†è¾¹ç•Œæƒ…å†µ"""
    # é¿å…é™¤é›¶é”™è¯¯
    weights = 1 / (distances + 1e-8)
    
    # ä½¿ç”¨å­—å…¸ç´¯åŠ æƒé‡ï¼Œæ—¶é—´å¤æ‚åº¦O(k)
    weight_sum = {}
    for label, weight in zip(labels, weights):
        weight_sum[label] = weight_sum.get(label, 0) + weight
    
    # è¿”å›æƒé‡æœ€å¤§çš„ç±»åˆ«
    return max(weight_sum.items(), key=lambda x: x[1])[0]
```

## âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. å‘é‡åŒ–è¿ç®—
- ä½¿ç”¨ `cdist` ä»£æ›¿æ‰‹åŠ¨å¾ªç¯è®¡ç®—è·ç¦»
- åˆ©ç”¨ `argpartition` è¿›è¡Œé«˜æ•ˆçš„éƒ¨åˆ†æ’åº
- ä½¿ç”¨å¸ƒå°”ç´¢å¼•å’Œæ•°ç»„æ“ä½œä»£æ›¿Pythonå¾ªç¯

### 2. å†…å­˜ä¼˜åŒ–
```python
# åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
def predict_batch(self, X, batch_size=1000):
    predictions = []
    for i in range(0, len(X), batch_size):
        batch = X[i:i+batch_size]
        pred_batch = self.predict(batch)
        predictions.extend(pred_batch)
    return np.array(predictions)
```

### 3. ç¼“å­˜ä¼˜åŒ–
```python
# ç¼“å­˜è·ç¦»è®¡ç®—ä¸­çš„ä¸­é—´ç»“æœ
def _compute_squared_distances(self, X):
    """è®¡ç®—å¹³æ–¹è·ç¦»ï¼Œé¿å…å¼€æ–¹è¿ç®—"""
    if not hasattr(self, '_X_train_squared'):
        self._X_train_squared = np.sum(self.X_train**2, axis=1)
    
    X_squared = np.sum(X**2, axis=1, keepdims=True)
    distances_squared = X_squared + self._X_train_squared - 2 * X.dot(self.X_train.T)
    return np.maximum(distances_squared, 0)  # é¿å…æ•°å€¼è¯¯å·®å¯¼è‡´çš„è´Ÿæ•°
```

## ğŸ¯ ç®—æ³•å¤æ‚åº¦åˆ†æ

### æ—¶é—´å¤æ‚åº¦
- **è®­ç»ƒé˜¶æ®µ**: O(1) - åªæ˜¯å­˜å‚¨æ•°æ®
- **é¢„æµ‹é˜¶æ®µ**: O(nd + n log k) 
  - n: æµ‹è¯•æ ·æœ¬æ•°
  - d: ç‰¹å¾ç»´åº¦
  - k: è¿‘é‚»æ•°

### ç©ºé—´å¤æ‚åº¦
- **è®­ç»ƒæ•°æ®å­˜å‚¨**: O(nd)
- **è·ç¦»çŸ©é˜µ**: O(nm) - mä¸ºè®­ç»ƒæ ·æœ¬æ•°

## ğŸ” è¾¹ç•Œæƒ…å†µå¤„ç†

### 1. è·ç¦»ä¸ºé›¶çš„æƒ…å†µ
```python
# åœ¨åŠ æƒæŠ•ç¥¨ä¸­å¤„ç†è·ç¦»ä¸ºé›¶çš„é‚»å±…
weights = 1 / (distances + 1e-8)  # æ·»åŠ å°å¸¸æ•°é¿å…é™¤é›¶
```

### 2. å¹³ç¥¨å¤„ç†
```python
def _break_tie(self, weight_sum):
    """åœ¨å¹³ç¥¨æ—¶é€‰æ‹©è·ç¦»æ›´è¿‘çš„ç±»åˆ«"""
    max_weight = max(weight_sum.values())
    candidates = [label for label, weight in weight_sum.items() 
                 if weight == max_weight]
    # é€‰æ‹©ç¬¬ä¸€ä¸ªå‡ºç°çš„ç±»åˆ«ï¼ˆæˆ–å¯ä»¥éšæœºé€‰æ‹©ï¼‰
    return candidates[0]
```

### 3. ç©ºæ•°æ®é›†éªŒè¯
```python
def fit(self, X, y):
    if len(X) == 0:
        raise ValueError("è®­ç»ƒæ•°æ®ä¸èƒ½ä¸ºç©º")
    if len(X) != len(y):
        raise ValueError("ç‰¹å¾å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
    self.X_train = np.array(X)
    self.y_train = np.array(y)
    return self
```

## ğŸ“ˆ æ‰©å±•åŠŸèƒ½

### æ¦‚ç‡é¢„æµ‹
```python
def predict_proba(self, X):
    """è¿”å›æ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡"""
    distances = self._compute_distances(X)
    indices = self._get_neighbor_indices(distances)
    
    probas = []
    for i, neighbor_indices in enumerate(indices):
        neighbor_labels = self.y_train[neighbor_indices]
        neighbor_distances = distances[i, neighbor_indices]
        
        if self.weights == 'uniform':
            # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ¯”ä¾‹
            class_counts = np.bincount(neighbor_labels)
            proba = class_counts / len(neighbor_labels)
        else:
            # åŸºäºè·ç¦»åŠ æƒçš„æ¦‚ç‡
            weights = 1 / (neighbor_distances + 1e-8)
            class_weights = np.bincount(neighbor_labels, weights=weights)
            proba = class_weights / np.sum(weights)
        
        probas.append(proba)
    
    return np.array(probas)
```